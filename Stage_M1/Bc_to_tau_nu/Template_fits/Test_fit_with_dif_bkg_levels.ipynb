{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "built-rouge",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import uproot\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.interpolate as interpolate\n",
    "import pickle\n",
    "import zfit\n",
    "import mplhep\n",
    "from numpy import random \n",
    "\n",
    "from matplotlib import rc\n",
    "rc('font',**{'family':'serif','serif':['Roman']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dress-guest",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dowloading the data\n",
    "bc_tree = uproot.open('root://eospublic.cern.ch//eos/experiment/fcc/ee/analyses/case-studies/flavour/Bc2TauNu/flatNtuples/spring2021/prod_04/Analysis_stage2/p8_ee_Zbb_ecm91_EvtGen_Bc2TauNuTAUHADNU.root')['events']\n",
    "bu_tree = uproot.open('root://eospublic.cern.ch//eos/experiment/fcc/ee/analyses/case-studies/flavour/Bc2TauNu/flatNtuples/spring2021/prod_04/Analysis_stage2/p8_ee_Zbb_ecm91_EvtGen_Bu2TauNuTAUHADNU.root')['events']\n",
    "bb_tree = uproot.open('root://eospublic.cern.ch//eos/experiment/fcc/ee/analyses/case-studies/flavour/Bc2TauNu/flatNtuples/spring2021/prod_04/Analysis_stage2/p8_ee_Zbb_ecm91_EvtGen.root')['events']\n",
    "cc_tree = uproot.open('root://eospublic.cern.ch//eos/experiment/fcc/ee/analyses/case-studies/flavour/Bc2TauNu/flatNtuples/spring2021/prod_04/Analysis_stage2/p8_ee_Zcc_ecm91.root')['events']\n",
    "\n",
    "tree_gen = uproot.open(\"root://eospublic.cern.ch//eos/experiment/fcc/ee/analyses/case-studies/flavour/Bc2TauNu/flatNtuples/spring2021/prod_04/Analysis_stage2/p8_ee_Zbb_ecm91_EvtGen_Bc2TauNuTAUHADNU.root\")[\"metadata\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saved-drunk",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforming the data into a dataframe\n",
    "bc_df = bc_tree.arrays(library=\"pd\", how=\"zip\", filter_name=[\"EVT_*\"])\n",
    "bu_df = bu_tree.arrays(library=\"pd\", how=\"zip\", filter_name=[\"EVT_*\"])\n",
    "bb_df = bb_tree.arrays(library=\"pd\", how=\"zip\", filter_name=[\"EVT_*\"])\n",
    "cc_df = cc_tree.arrays(library=\"pd\", how=\"zip\", filter_name=[\"EVT_*\"])\n",
    "\n",
    "#Getting general information on the data\n",
    "df_gen = tree_gen.arrays(library=\"pd\", how=\"zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "according-channel",
   "metadata": {},
   "source": [
    "### Initialization of the data parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gothic-penalty",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We consider as initial data the data whose MVAs are between 0.95 and 1\n",
    "bc_sig = bc_df[bc_df['EVT_MVA2']> 0.95]\n",
    "bc_sig = bc_sig[bc_sig['EVT_MVA1']> 0.95]\n",
    "\n",
    "bu_bkg = bu_df[bu_df['EVT_MVA2']> 0.95]\n",
    "bu_bkg = bu_bkg[bu_bkg['EVT_MVA1']> 0.95] \n",
    "\n",
    "bb_bkg = bb_df[bb_df['EVT_MVA2']> 0.95]\n",
    "bb_bkg = bb_bkg[bb_bkg['EVT_MVA1']> 0.95] \n",
    "\n",
    "cc_bkg = cc_df[cc_df['EVT_MVA2']> 0.95]\n",
    "cc_bkg = cc_bkg[cc_bkg['EVT_MVA1']> 0.95] \n",
    "\n",
    "qq_bkg = qq_df[qq_df['EVT_MVA2']> 0.95]\n",
    "qq_bkg = qq_bkg[qq_bkg['EVT_MVA1']> 0.95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "important-hostel",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of Z0 produced\n",
    "N_Z0_init = 5*10**(12)\n",
    "N_Z0 = 5*10**(11)\n",
    "\n",
    "#Branching fraction Z->quark-pair\n",
    "BF_Zbb = 0.1512\n",
    "BF_Zcc = 0.1203\n",
    "BF_Zqq = 0.4276\n",
    "\n",
    "#Production ratio of Bc+ and B+\n",
    "f_Bc = 0.0004\n",
    "f_Bu = 0.43\n",
    "\n",
    "#Branching fraction Bc+->tau nu B+->tau nu and tau->3pions\n",
    "BF_Bctaunu = 0.0194\n",
    "BF_Butaunu = 1.09*10**(-4)\n",
    "BF_tau3pion = 0.0931\n",
    "\n",
    "#Definition of the functions computing the different yields\n",
    "def S_bc_cut(initial_eff, cut_eff) :\n",
    "    return (N_Z0*BF_Zbb*2*f_Bc*BF_Bctaunu*BF_tau3pion)*initial_eff*cut_eff\n",
    "\n",
    "def B_bu_cut(initial_eff, cut_eff) :\n",
    "    return (N_Z0*BF_Zbb*2*f_Bu*BF_Butaunu*BF_tau3pion)*initial_eff*cut_eff\n",
    "\n",
    "def B_bb_cut(initial_eff, cut_eff) :\n",
    "    return (N_Z0*BF_Zbb*2)*initial_eff*cut_eff\n",
    "\n",
    "def B_cc_cut(initial_eff, cut_eff) :\n",
    "    return (N_Z0*BF_Zcc*2)*initial_eff*cut_eff\n",
    "\n",
    "def B_qq_cut(initial_eff, cut_eff) :\n",
    "    return (N_Z0*BF_Zqq*2)*initial_eff*cut_eff\n",
    "\n",
    "#Dowloading the splines to compute the number of inclusive background events\n",
    "bb_spline_MVA1_log = pickle.load(open(r'../Finding_the_best_MVA_cut/2D_plot/Spline_functions/MVA1_spline_log.pkl','rb'))\n",
    "bb_spline_MVA2_log = pickle.load(open(r'/Users/mariehartmann/Stage_M1/Stage_M1/Bc_to_tau_nu/Finding_the_best_MVA_cut/2D_plot/Spline_functions/MVA2_spline_log.pkl','rb'))\n",
    "\n",
    "cc_spline_MVA1_log = pickle.load(open(r'/Users/mariehartmann/Stage_M1/Stage_M1/Bc_to_tau_nu/Finding_the_best_MVA_cut/2D_plot/Spline_functions/cc_MVA1_spline_log.pkl','rb'))\n",
    "cc_spline_MVA2_log = pickle.load(open(r'/Users/mariehartmann/Stage_M1/Stage_M1/Bc_to_tau_nu/Finding_the_best_MVA_cut/2D_plot/Spline_functions/cc_MVA2_spline_log.pkl','rb'))\n",
    "\n",
    "#Initialization of the number of events in the MVAs for all contributions\n",
    "nb_total_events = df_gen.iloc[0][\"eventsProcessed\"]\n",
    "nb_bc_events = len(bc_sig)\n",
    "nb_bu_events = len(bu_bkg)\n",
    "nb_bb_events = len(bb_bkg)\n",
    "nb_cc_events = len(cc_bkg)\n",
    "\n",
    "#Initialization of the number of events for both MVAs for inclusive backgrounds\n",
    "nb_bb_events_1 = interpolate.splint(-np.log(1-0.95), 9, bb_spline_MVA1_log)\n",
    "nb_cc_events_1 = interpolate.splint(-np.log(1-0.95), 9, cc_spline_MVA1_log)\n",
    "\n",
    "nb_bb_events_2 = interpolate.splint(-np.log(1-0.95), 8, bb_spline_MVA2_log)\n",
    "nb_cc_events_2 = interpolate.splint(-np.log(1-0.95), 7, cc_spline_MVA2_log)\n",
    "\n",
    "#Computing of the initial efficiencies for all backgrounds\n",
    "initial_eff_bc_sig = nb_bc_events / nb_total_events\n",
    "initial_eff_bu_bkg = nb_bu_events / nb_total_events\n",
    "initial_eff_bb_bkg = nb_bb_events / nb_total_events\n",
    "initial_eff_cc_bkg = nb_cc_events / nb_total_events\n",
    "\n",
    "print('eff sig {}'.format(initial_eff_bc_sig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intended-entrepreneur",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimized MVAs\n",
    "Optimized_MVA1 = 0.9998599999999961  #+-0.00001\n",
    "Optimized_MVA2 = 0.9963399999999984 #+-0.00001\n",
    "\n",
    "Optimized_MVA1_log = -np.log(1-Optimized_MVA1)\n",
    "Optimized_MVA2_log = -np.log(1-Optimized_MVA2)\n",
    "\n",
    "\n",
    "#Applying the MVA2 cut on the dataframe\n",
    "df_bc_sig = bc_sig[bc_sig['EVT_MVA1']>Optimized_MVA1]\n",
    "df_bc_sig = df_bc_sig[df_bc_sig['EVT_MVA2']>Optimized_MVA2]\n",
    "\n",
    "df_bu_bkg = bu_bkg[bu_bkg['EVT_MVA1']>Optimized_MVA1]\n",
    "df_bu_bkg = df_bu_bkg[df_bu_bkg['EVT_MVA2']>Optimized_MVA2]\n",
    "          \n",
    "    \n",
    "#Counting the number of events in the Bc+ and B+ dataframes after the cut\n",
    "nb_bc_after_cut = len(df_bc_sig)\n",
    "nb_bu_after_cut = len(df_bu_bkg)\n",
    "        \n",
    "    \n",
    "#Counting the number of events left for each MVAs for inclusive backgrounds\n",
    "nb_bb_after_cut_1 = interpolate.splint(Optimized_MVA1_log, 9, bb_spline_MVA1_log)\n",
    "nb_bb_after_cut_2 = interpolate.splint(Optimized_MVA2_log, 8, bb_spline_MVA2_log)\n",
    "        \n",
    "nb_cc_after_cut_1 = interpolate.splint(Optimized_MVA1_log, 9, cc_spline_MVA1_log)\n",
    "nb_cc_after_cut_2 = interpolate.splint(Optimized_MVA2_log, 7, cc_spline_MVA2_log)\n",
    "\n",
    "\n",
    "#Computing the efficiencies\n",
    "cut_eff_bc_sig = nb_bc_after_cut / nb_bc_events\n",
    "        \n",
    "cut_eff_bu_bkg = nb_bu_after_cut / nb_bu_events\n",
    "cut_eff_bb_bkg = (nb_bb_after_cut_1 / nb_bb_events_1) * (nb_bb_after_cut_2 / nb_bb_events_2)\n",
    "cut_eff_cc_bkg = (nb_cc_after_cut_1 / nb_cc_events_1) * (nb_cc_after_cut_2 / nb_cc_events_2)\n",
    "print(cut_eff_bu_bkg)\n",
    "print(cut_eff_bb_bkg)\n",
    "print(cut_eff_cc_bkg)\n",
    "        \n",
    "    \n",
    "#Signal, Background and Purity\n",
    "S = S_bc_cut(initial_eff_bc_sig, cut_eff_bc_sig)\n",
    "B = B_bb_cut(initial_eff_bb_bkg, cut_eff_bb_bkg) + B_cc_cut(initial_eff_cc_bkg, cut_eff_cc_bkg) + B_bu_cut(initial_eff_bu_bkg, cut_eff_bu_bkg) #+ B_qq_cut(initial_eff_qq_bkg, cut_eff_qq_bkg)\n",
    "P = S/(S+B)\n",
    "\n",
    "print('Number of signal events = {}'.format(S))\n",
    "print('Number of bkg events = {}'.format(B))\n",
    "print('Purity = {}'.format(P))\n",
    "\n",
    "N_BC = S_bc_cut(initial_eff_bc_sig, cut_eff_bc_sig)\n",
    "\n",
    "N_BU = B_bu_cut(initial_eff_bu_bkg, cut_eff_bu_bkg)\n",
    "N_BB = B_bb_cut(initial_eff_bb_bkg, cut_eff_bb_bkg)\n",
    "N_CC = B_cc_cut(initial_eff_cc_bkg, cut_eff_cc_bkg)\n",
    "\n",
    "N_BB_CC = N_BB + N_CC\n",
    "\n",
    "print('N_BC = {}'.format(N_BC))\n",
    "print('N_BU = {}'.format(N_BU))\n",
    "print('N_BB = {}'.format(N_BB))\n",
    "print('N_CC = {}'.format(N_CC))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjusted-taste",
   "metadata": {},
   "source": [
    "### Creating the templates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "touched-inventory",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-hierarchy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Param√®tres pour les histogrammes\n",
    "variable = 'EVT_ThrustEmax_E'\n",
    "nb_bins = int(40/np.sqrt(N_Z0_init/N_Z0))\n",
    "min_bin = 20\n",
    "max_bin = 50\n",
    "\n",
    "name_bc = r\"$B_c^+$ $\\rightarrow$ $\\tau^+$ $\\nu$ \"\n",
    "name_bu = r\"$B^+$ $\\rightarrow$ $\\tau^+$ $\\nu$ \"\n",
    "name_bb = r\"$Z^0$ $\\rightarrow$ $b\\bar{b}$ \"\n",
    "name_cc = r\"$Z^0$ $\\rightarrow$ $c\\bar{c}$ \"\n",
    "\n",
    "colour_bc = \"#756bb1\"\n",
    "colour_bu = \"#3182bd\"\n",
    "colour_bb = \"#43a2ca\" \n",
    "colour_cc = \"#9ecae1\" \n",
    "\n",
    "#Stocker la forme th√©orique (ie simul√©e) des diff√©rentes contributions\n",
    "counts_bc, bins_bc = np.histogram(bc_sig[variable], bins = nb_bins, range = (min_bin, max_bin))\n",
    "counts_bu, bins_bu = np.histogram(bu_bkg[variable], bins = nb_bins, range = (min_bin, max_bin))\n",
    "counts_bb, bins_bb = np.histogram(bb_bkg[variable], bins = nb_bins, range = (min_bin, max_bin))\n",
    "counts_cc, bins_cc = np.histogram(cc_bkg[variable], bins = nb_bins, range = (min_bin, max_bin))\n",
    "\n",
    "counts_bc = (counts_bc/np.sum(counts_bc)) * N_BC\n",
    "counts_bu = (counts_bu/np.sum(counts_bu)) * N_BU\n",
    "counts_bb = (counts_bb/np.sum(counts_bb)) * N_BB\n",
    "counts_cc = (counts_cc/np.sum(counts_cc)) * N_CC\n",
    "\n",
    "#Uniformiser les bin_edges\n",
    "x = [bins_cc[:-1], bins_bb[:-1], bins_bu[:-1], bins_bc[:-1]]\n",
    "bins = bins_bc\n",
    "weights = [counts_cc, counts_bb, counts_bu, counts_bc ]\n",
    "colour = [colour_cc, colour_bb, colour_bu, colour_bc]\n",
    "name = [name_cc, name_bb, name_bu, name_bc]\n",
    "\n",
    "plt.figure()\n",
    "counts, bin_edges, _ = plt.hist(x, bins, weights=weights, color=colour, label=name, stacked=True)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cathedral-george",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the right bins_edges size\n",
    "_ , bins_edges = np.histogram(a=bin_edges[:-1], bins=bin_edges, weights=counts[3])\n",
    "\n",
    "#Templates and templates normalisation from the predicted simulated data.\n",
    "template_yield_bc, _ = np.histogram(a=bins_bc[:-1], bins=bins_edges, weights=counts_bc)\n",
    "template_yield_bu, _ = np.histogram(a=bins_bu[:-1], bins=bins_edges, weights=counts_bu)\n",
    "template_yield_bb, _ = np.histogram(a=bins_bb[:-1], bins=bins_edges, weights=counts_bb)\n",
    "template_yield_cc, _ = np.histogram(a=bins_cc[:-1], bins=bins_edges, weights=counts_cc)\n",
    "    \n",
    "template_yield_bc = template_yield_bc/np.sum(template_yield_bc)\n",
    "template_yield_bu = template_yield_bu/np.sum(template_yield_bu)\n",
    "template_yield_bb = template_yield_bb/np.sum(template_yield_bb)\n",
    "template_yield_cc = template_yield_cc/np.sum(template_yield_cc)\n",
    " \n",
    "#Checking if there are zero bins    \n",
    "print(template_yield_bc)\n",
    "print(template_yield_bu)\n",
    "print(template_yield_bb)\n",
    "print(template_yield_cc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foster-comparison",
   "metadata": {},
   "source": [
    "##### Creating the function that we will use for the fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressive-heavy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#When considering Z->bb, Z->cc and Bu for background\n",
    "def get_template(yield_bc, yield_bu, yield_bb_cc): \n",
    "    return yield_bc*template_yield_bc + yield_bu*template_yield_bu + yield_bb_cc*((N_BB/N_BB_CC)*template_yield_bb + (N_CC/N_BB_CC)*template_yield_cc)\n",
    "    \n",
    "def binned_nll(template, sample_hist):\n",
    "    return np.sum(template - sample_hist + sample_hist * np.log((sample_hist + 1*10**(-14)) / (template + 1*10**(-14))))\n",
    "  # 1e-14 added in case there are empty bins\n",
    "\n",
    "def loss(x):\n",
    "    # by default, `x` is an `OrderedSet` of zfit parameters.\n",
    "    x = np.array(x)\n",
    "\n",
    "    print(\"Value of the parameters\", x)\n",
    "  \n",
    "    # The first parameter is the Bc yield \n",
    "    yield_bc = x[0]\n",
    "    # The second parameter is the Bu yield \n",
    "    yield_bu = x[1]\n",
    "    # The second parameter is the Z->bb and Z->cc combined yield \n",
    "    yield_bb_cc = x[2]\n",
    "\n",
    "    template = get_template(yield_bc, yield_bu, yield_bb_cc)\n",
    "\n",
    "    nll = binned_nll(template, sample_hist)\n",
    "    \n",
    "    #Gaussian constraint on B+ -> tau nu yield\n",
    "    nll += (yield_bu - N_BU)**2/2./N_BU*0.05\n",
    "\n",
    "    return nll\n",
    "\n",
    "loss.errordef = 0.5 # 0.5 for a log-likelihood\n",
    "# We would set this parameter at 1 for a chi2 loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acceptable-withdrawal",
   "metadata": {},
   "source": [
    "##### Toy samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interim-evaluation",
   "metadata": {},
   "source": [
    "Playing on the value of the background yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technological-prerequisite",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Theoretical value of the yields parameters to give initial value to the fit parameters\n",
    "print('N_BC = {}'.format(N_BC))\n",
    "print('N_BU = {}'.format(N_BU))\n",
    "print('N_BB_CC = {}'.format(N_BB_CC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "antique-kennedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Faire √ßa pour 10, 5, 1/5 et 1/10\n",
    "bkg_var = 10\n",
    "\n",
    "\n",
    "#Initialisation des param√®tres de la boucle\n",
    "n_loop = 2000\n",
    "new_bc_yield = np.zeros(n_loop)\n",
    "new_bu_yield = np.zeros(n_loop)\n",
    "new_bb_cc_yield = np.zeros(n_loop)\n",
    "\n",
    "\n",
    "#Initialisation des \"donn√©es experimentales\" pour un level de bkg diff√©rent de ce qu'on a avec la simulation\n",
    "new_bc_yield_error = np.zeros(n_loop)\n",
    "new_bu_yield_error = np.zeros(n_loop)\n",
    "new_bb_cc_yield_error = np.zeros(n_loop)\n",
    "\n",
    "new_counts_bc = (counts_bc/np.sum(counts_bc)) * N_BC\n",
    "new_counts_bu = (counts_bu/np.sum(counts_bu)) * N_BU\n",
    "new_counts_bb = (counts_bb/np.sum(counts_bb)) * N_BB * bkg_var\n",
    "new_counts_cc = (counts_cc/np.sum(counts_cc)) * N_CC * bkg_var\n",
    "\n",
    "x = [bins_cc[:-1], bins_bb[:-1], bins_bu[:-1], bins_bc[:-1]]\n",
    "bins = bins_edges\n",
    "weights = [new_counts_cc, new_counts_bb, new_counts_bu, new_counts_bc ]\n",
    "colour = [colour_cc, colour_bb, colour_bu, colour_bc]\n",
    "name = [name_cc, name_bb, name_bu, name_bc]\n",
    "\n",
    "plt.figure()\n",
    "new_counts, new_bin_edges, _ = plt.hist(x, bins, weights=weights, color=colour, label=name, stacked=True)\n",
    "plt.plot()\n",
    "\n",
    "\n",
    "#Boucle sur les toy samples\n",
    "for i in range (n_loop) :\n",
    "    \n",
    "    #Toy sample\n",
    "    data = np.random.poisson(new_counts[3])\n",
    "    sample_hist, bins_edges = np.histogram(a=new_bin_edges[:-1], bins=new_bin_edges, weights=data)\n",
    "\n",
    "    #Initialisation of the parameters\n",
    "    i_rand = random.randint(0,1000000000000,size=1)\n",
    "    \n",
    "    initial_params = {\n",
    "            'value': [400, 20, 400],\n",
    "            'lower' : [-1000., -1000., -1000.], # optional\n",
    "            'upper': [10000., 10000., 10000.], # optional\n",
    "            'name': [f\"bc_yield_{i_rand}\", f\"bu_yield_{i_rand}\", f\"bb_cc_yield_{i_rand}\"] # optional\n",
    "        }\n",
    "\n",
    "    #Fit\n",
    "    minimiser = zfit.minimize.Minuit(verbosity=5)\n",
    "    zfit.run.set_autograd_mode(False)\n",
    "    zfit.run.set_graph_mode(False)\n",
    "    \n",
    "    #Extracting the informations\n",
    "    result = minimiser.minimize(loss, initial_params)\n",
    "    params = result.params\n",
    "    params_hesse = result.hesse() #Computation of the errors\n",
    "    corr = result.correlation(method=\"minuit_hesse\")\n",
    "    \n",
    "    print(result.info['original'])\n",
    "    print(params)\n",
    "    print('correction {}'.format(corr))\n",
    "\n",
    "    #Extracting the yield results\n",
    "    new_bc_yield[i] = params[f\"bc_yield_{i_rand}\"]['value']\n",
    "    new_bu_yield[i] = params[f\"bu_yield_{i_rand}\"]['value']\n",
    "    new_bb_cc_yield[i] = params[f\"bb_cc_yield_{i_rand}\"]['value']\n",
    "    \n",
    "    new_bc_yield_error[i] = params[f\"bc_yield_{i_rand}\"]['minuit_hesse']['error']\n",
    "    new_bu_yield_error[i] = params[f\"bu_yield_{i_rand}\"]['minuit_hesse']['error']\n",
    "    new_bb_cc_yield_error[i] = params[f\"bb_cc_yield_{i_rand}\"]['minuit_hesse']['error']\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sorted-riding",
   "metadata": {},
   "source": [
    "##### Signal yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "following-albert",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(new_bc_yield, histtype='step', color=\"#1c9099\")\n",
    "plt.xlabel('Signal Yield')\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threaded-listing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Espace observable et data\n",
    "min_sig = -3 #int(sig_yield.min())\n",
    "max_sig = 3 #int(sig_yield.max()) + 1\n",
    "obs = zfit.Space('x', limits=(min_sig,max_sig))\n",
    "data = zfit.Data.from_numpy(obs=obs, array=new_bc_yield, weights=None) #\n",
    "\n",
    "#D√©finition des param√®tres\n",
    "rand_int = random.randint(0,1000000,size=1)\n",
    "mu_sig_ = zfit.Parameter(f\"mu_sig_{rand_int}\", 0.)\n",
    "sigma_sig_ = zfit.Parameter(f\"sigma_sig_{rand_int}\", 3.)\n",
    "\n",
    "#Fits\n",
    "gauss = zfit.pdf.Gauss(obs=obs, mu=mu_sig_, sigma=sigma_sig_)\n",
    "nll = zfit.loss.UnbinnedNLL(model=gauss, data=data )\n",
    "minimizer = zfit.minimize.Minuit()\n",
    "result_sig = minimizer.minimize(nll)\n",
    "\n",
    "print(result_sig.info['original'])\n",
    "print(result_sig.params)\n",
    "\n",
    "#Plots\n",
    "\n",
    "#Param√®tre des histogrammes\n",
    "nb_bins = 100\n",
    "lower, upper = obs.limits\n",
    "colour_bc = \"#fdae61\"\n",
    "\n",
    "#Points du fit des yields de Bc+\n",
    "x_plot_sig = np.linspace(lower[0][0], upper[0][0], num=1000)\n",
    "y_plot_sig = zfit.run(gauss.pdf(x_plot_sig, norm_range=obs))\n",
    "\n",
    "#Points de l'histogramme des yields de Bc+\n",
    "counts_sig, bin_edges_sig = np.histogram(new_bc_yield, bins=nb_bins, range=(lower[0][0], upper[0][0]))\n",
    "#\n",
    "\n",
    "#Trac√© du plot\n",
    "plt.figure(figsize = [8,6])\n",
    "\n",
    "mplhep.histplot((counts_sig, bin_edges_sig), \n",
    "                yerr = True, \n",
    "                color = colour_bc, \n",
    "                histtype='errorbar', \n",
    "                label=\"Simulated results\")\n",
    "\n",
    "plt.plot(x_plot_sig, \n",
    "         y_plot_sig * (len(new_bc_yield)/nb_bins*obs.area()), #\n",
    "         color= colour_bc, \n",
    "         label= \"Fit\")\n",
    "\n",
    "plt.xlabel(\"Signal yield\")\n",
    "plt.ylabel(\"Number of events\")\n",
    "plt.title(\"Signal yield with a background level = {}\".format(N_BB_CC * bkg_var))\n",
    "plt.xlim(lower[0][0], upper[0][0])\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "descending-temple",
   "metadata": {},
   "source": [
    "##### $B^+$ $\\rightarrow$ $\\tau$ $\\nu_\\tau$ Yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boxed-burning",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(new_bu_yield, histtype='step', color=\"#1c9099\")\n",
    "plt.xlabel(r'$B^+$ $\\rightarrow$ $\\tau$ $\\nu_\\tau$ Yield')\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varying-myrtle",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Espace observable et data\n",
    "min_bu = -0.3 #int(sig_yield.min())\n",
    "max_bu = 0.3 #int(sig_yield.max())\n",
    "obs_bu = zfit.Space('x', limits=(min_bu, max_bu))\n",
    "data_bu = zfit.Data.from_numpy(obs=obs_bu, array=new_bu_yield, weights=None)\n",
    "\n",
    "#D√©finition des param√®tres\n",
    "rand_int = random.randint(0,1000000,size=1)\n",
    "mu_bu_ = zfit.Parameter(f\"mu_bu_{rand_int}\", 0.)\n",
    "sigma_bu_ = zfit.Parameter(f\"sigma_bu_{rand_int}\", 0.1)\n",
    "\n",
    "#Fits\n",
    "gauss = zfit.pdf.Gauss(obs=obs_bu, mu=mu_bu_, sigma=sigma_bu_)\n",
    "nll = zfit.loss.UnbinnedNLL(model=gauss, data=data_bu )\n",
    "minimizer = zfit.minimize.Minuit()\n",
    "result_bu = minimizer.minimize(nll)\n",
    "\n",
    "print(result_bu.info['original'])\n",
    "print(result_bu.params)\n",
    "\n",
    "#Plots\n",
    "\n",
    "#Param√®tre des histogrammes\n",
    "nb_bins = 100\n",
    "lower, upper = obs_bu.limits\n",
    "colour_bu = \"#74add1\"\n",
    "label_bu = r'$B^+$ $\\rightarrow$ $\\tau$ $\\nu_\\tau$ yield'\n",
    "\n",
    "#Points du fit des yields de B+\n",
    "x_plot_bu = np.linspace(lower[0][0], upper[0][0], num=1000)\n",
    "y_plot_bu = zfit.run(gauss.pdf(x_plot_bu, norm_range=obs_bu))\n",
    "\n",
    "#Points de l'histogramme des yields de B+\n",
    "counts_bu, bin_edges_bu = np.histogram(new_bu_yield, bins=nb_bins, range=(lower[0][0], upper[0][0]))\n",
    "\n",
    "#Trac√© du plot\n",
    "plt.figure(figsize = [8,6])\n",
    "\n",
    "mplhep.histplot((counts_bu, bin_edges_bu),\n",
    "                yerr = True, \n",
    "                color = colour_bu, \n",
    "                histtype='errorbar', \n",
    "                label=\"Simulated results\")\n",
    "\n",
    "plt.plot(x_plot_bu, \n",
    "         y_plot_bu * (len(new_bu_yield)/nb_bins*obs_bu.area()), \n",
    "         color= colour_bu, \n",
    "         label= \"Fit\")\n",
    "\n",
    "plt.xlabel(label_bu)\n",
    "plt.ylabel(\"Number of events\")\n",
    "plt.title(r\"$B^+$ $\\rightarrow$ $\\tau$ $\\nu_\\tau$ yield with a background level = {}\".format(N_BB_CC * bkg_var))\n",
    "plt.xlim(lower[0][0], upper[0][0])\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outstanding-optimization",
   "metadata": {},
   "source": [
    "##### Background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "objective-durham",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(new_bb_cc_yield, histtype='step', color=\"#756bb1\")\n",
    "plt.xlabel(r'$Z^0$ $\\rightarrow$ $b\\bar{b}$ and $Z^0$ $\\rightarrow$ $c\\bar{c}$ background yield')\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "still-relief",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Espace observable et data\n",
    "min_bkg = -3 #int(bkg_yield.min())\n",
    "max_bkg = 3 #int(bkg_yield.max()) + 1\n",
    "obs_bkg = zfit.Space('x', limits=(min_bkg,max_bkg))\n",
    "data = zfit.Data.from_numpy(obs=obs_bkg, array=new_bb_cc_yield, weights=None)\n",
    "\n",
    "#D√©finition des param√®tres\n",
    "rand_int = random.randint(0,1000000,size=1)\n",
    "mu_bkg_ = zfit.Parameter(f\"mu_bkg_{rand_int}\", 0.)\n",
    "\n",
    "rand_int = random.randint(0,1000000,size=1)\n",
    "sigma_bkg_ = zfit.Parameter(f\"sigma_bkg_{rand_int}\", 5.)\n",
    "\n",
    "#Fits\n",
    "gauss = zfit.pdf.Gauss(obs=obs_bkg, mu=mu_bkg_, sigma=sigma_bkg_)\n",
    "nll = zfit.loss.UnbinnedNLL(model=gauss, data=data )\n",
    "minimizer = zfit.minimize.Minuit()\n",
    "result_bkg = minimizer.minimize(nll)\n",
    "\n",
    "print(result_bkg.info['original'])\n",
    "print(result_bkg.params)\n",
    "\n",
    "#Plots\n",
    "\n",
    "#Param√®tre des histogrammes\n",
    "nb_bins = 100\n",
    "lower, upper = obs_bkg.limits\n",
    "colour_bb_cc = \"#4575b4\"#\"#abd9e9\"\n",
    "label_bb_cc = r\"$Z^0$ $\\rightarrow$ b$\\bar{b}$ and $Z^0$ $\\rightarrow$ c$\\bar{c}$ background yield\"\n",
    "\n",
    "#Points du fit des yields de Z->bb et Z->cc\n",
    "x_plot_bkg = np.linspace(lower[0][0], upper[0][0], num=1000)\n",
    "y_plot_bkg = zfit.run(gauss.pdf(x_plot_bkg, norm_range=obs_bkg))\n",
    "\n",
    "#Points de l'histogramme des yields de Z->bb et Z->cc\n",
    "counts_bkg, bin_edges_bkg = np.histogram(new_bb_cc_yield, bins=nb_bins, range=(lower[0][0], upper[0][0]))\n",
    "\n",
    "#Trac√© du plot\n",
    "plt.figure(figsize=[8,6])\n",
    "\n",
    "mplhep.histplot((counts_bkg, bin_edges_bkg), \n",
    "                yerr = True, \n",
    "                color = colour_bb_cc, \n",
    "                histtype='errorbar', \n",
    "                label=\"Simulated results\")\n",
    "\n",
    "plt.plot(x_plot_bkg, \n",
    "         y_plot_bkg * (len(new_bb_cc_yield)/nb_bins*obs_bkg.area()), \n",
    "         color= colour_bb_cc, \n",
    "         label= \"Fit\")\n",
    "\n",
    "\n",
    "plt.xlabel(label_bb_cc)\n",
    "plt.ylabel(\"Number of events\")\n",
    "plt.xlim(lower[0][0], upper[0][0])\n",
    "plt.legend()\n",
    "title_bb_cc = r\"$Z^0$ $\\rightarrow$ $b\\bar{}$ and $Z^0$ $\\rightarrow$ $c\\bar{}$ yield with a background level = {}\".format(\"b\", \"c\", N_BB_CC * bkg_var)\n",
    "#r\"$Z^0$ $\\rightarrow$ $b\\bar{b}$ and $Z^0$ $\\rightarrow$ $c\\bar{c}$ yield pull distribution with N($Z^0$)={:.0e}\".format(N_Z0)\n",
    "plt.title(title_bb_cc)\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
